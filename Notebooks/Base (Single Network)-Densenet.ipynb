{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c0c27b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import shutil\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "\n",
    "import math\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "from sklearn.utils import shuffle, class_weight\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from PIL import Image\n",
    "from tqdm import tqdm,tnrange,tqdm_notebook\n",
    "import tensorflow as tf\n",
    "from tqdm.keras import TqdmCallback\n",
    "from tensorflow.keras import backend as K \n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras import applications as app\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten,AveragePooling2D#, CenterCrop\n",
    "from tensorflow.keras.layers.experimental.preprocessing import CenterCrop\n",
    "from tensorflow.keras.layers import Dense,BatchNormalization,Dropout \n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.applications import EfficientNetB4, ResNet50, ResNet101, VGG16, MobileNet, InceptionV3, EfficientNetB2, densenet, ConvNeXtTiny\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "%matplotlib inline\n",
    "%matplotlib inline\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.subplots as sp\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "model_type = 'densenet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d225229f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Helper functions (run me)\n",
    "\n",
    "def set_device():\n",
    "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "  if device != \"cuda\":\n",
    "      print(\"WARNING: For this notebook to perform best, \"\n",
    "          \"if possible, in the menu under `Runtime` -> \"\n",
    "          \"`Change runtime type.`  select `GPU` \")\n",
    "  else:\n",
    "      print(\"GPU is enabled in this notebook.\")\n",
    "\n",
    "  return device\n",
    "\n",
    "def set_device_tf():    \n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "      # Restrict TensorFlow to only use the first GPU\n",
    "      try:\n",
    "        tf.config.experimental.set_visible_devices(gpus, 'GPU')\n",
    "        print(gpus)\n",
    "      except RuntimeError as e:\n",
    "        # Visible devices must be set at program startup\n",
    "        print(e)\n",
    "    else:\n",
    "      print(\"No GPUs found\")\n",
    "\n",
    "#  Plotting function.\n",
    "def plot_accuracy_and_loss(history):\n",
    "  acc = history.history['accuracy']\n",
    "  val_acc = history.history['val_accuracy']\n",
    "\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  plt.figure(figsize=(8, 8))\n",
    "  plt.subplot(2, 1, 1)\n",
    "  plt.plot(acc, label='Training')\n",
    "  plt.plot(val_acc, label='Validation')\n",
    "  plt.legend(loc='lower right')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.ylim([min(plt.ylim()),1.05])\n",
    "  plt.title('Training and Validation Accuracy')\n",
    "\n",
    "  plt.subplot(2, 1, 2)\n",
    "  plt.plot(loss, label='Training')\n",
    "  plt.plot(val_loss, label='Validation')\n",
    "  plt.legend(loc='upper right')\n",
    "  plt.ylabel('Cross Entropy')\n",
    "  plt.ylim([np.min(np.concatenate((val_loss,loss)))-0.1,np.max(np.concatenate((val_loss,loss)))+0.1])\n",
    "  plt.title('Training and Validation Loss')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.show()\n",
    "  plt.close('all')\n",
    "\n",
    "def plot_accuracy_and_loss_plotly(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    # Create subplots\n",
    "    fig = sp.make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        subplot_titles=('Training and Validation Accuracy', 'Training and Validation Loss'),\n",
    "        shared_xaxes=True,  # This makes the x-axis (epoch) shared among the two plots\n",
    "    )\n",
    "\n",
    "    # Add traces for accuracy\n",
    "    fig.add_trace(\n",
    "        go.Scatter(y=acc, mode='lines', name='Training', line=dict(color='blue'), legendgroup='Training'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(y=val_acc, mode='lines', name='Validation', line=dict(color='red'), legendgroup='Validation'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # Add traces for loss\n",
    "    fig.add_trace(\n",
    "        go.Scatter(y=loss, mode='lines', showlegend=False, line=dict(color='blue'), legendgroup='Training'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(y=val_loss, mode='lines', showlegend=False, line=dict(color='red'), legendgroup='Validation'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        height=600,\n",
    "        width=800,\n",
    "        margin=dict(t=50, b=50, l=50, r=50),\n",
    "        paper_bgcolor='white',  # Set background color to white\n",
    "        plot_bgcolor='white',   # Set plot background color to white\n",
    "    )\n",
    "\n",
    "    # Update y-axis labels, grid, and range\n",
    "    fig.update_yaxes(\n",
    "        title_text=\"Accuracy\", row=1, col=1, \n",
    "        showgrid=True, gridwidth=1, gridcolor='LightGrey', \n",
    "        range=[0.45, 0.92]  # Custom y-axis range for top subplot\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        title_text=\"Cross Entropy\", row=2, col=1, \n",
    "        showgrid=True, gridwidth=1, gridcolor='LightGrey', \n",
    "        range=[0.19, 1.25]  # Custom y-axis range for bottom subplot\n",
    "    )\n",
    "\n",
    "    # Update x-axis label for the bottom plot and grid\n",
    "    fig.update_xaxes(title_text=\"Epoch\", row=2, col=1, showgrid=True, gridwidth=1, gridcolor='LightGrey')\n",
    "    fig.update_xaxes(title_text=\"\", row=1, col=1, showgrid=True, gridwidth=1, gridcolor='LightGrey')  # Added grid for top plot\n",
    "\n",
    "    # Show figure\n",
    "    fig.show()\n",
    "    pio.write_image(fig, \"Result Images/auc_plotly.png\", scale=2)  # Use scale parameter to increase resolution\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0eb01a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_device_tf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d4903b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data loading.\n",
    "def load_data(train_dir, test_dir):\n",
    "  BATCH_SIZE = 32 # 64 can fill up GPU memory!\n",
    "  IMG_SIZE = (224, 224)\n",
    "  AUTOTUNE = tf.data.AUTOTUNE\n",
    "    \n",
    "  if train_dir is not None:\n",
    "    train_dataset = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
    "                                                                  shuffle=True,\n",
    "                                                                  validation_split=.2, ##RECENT CHANGE\n",
    "                                                                  seed=123,\n",
    "                                                                  subset='training',\n",
    "                                                                  batch_size=BATCH_SIZE,\n",
    "                                                                  image_size=IMG_SIZE)\n",
    "\n",
    "    validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
    "                                                                  shuffle=True,\n",
    "                                                                  validation_split=.2, ##RECENT CHANGE\n",
    "                                                                  seed=123,\n",
    "                                                                  subset='validation',\n",
    "                                                                  batch_size=BATCH_SIZE,\n",
    "                                                                  image_size=IMG_SIZE)\n",
    "    train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    print('Number of train batches: %d' % tf.data.experimental.cardinality(train_dataset))\n",
    "  else:\n",
    "    train_dataset = None\n",
    "    validation_dataset = None\n",
    "        \n",
    "  if test_dir is not None:\n",
    "    test_dataset = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
    "                                                                  shuffle=False,\n",
    "                                                                  image_size=IMG_SIZE)\n",
    "    test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "  else:\n",
    "    test_dataset = None\n",
    "\n",
    "  return train_dataset, validation_dataset, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ea8cb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_weights(train_dataset, validation_dataset):\n",
    "  num_fails = 0\n",
    "  num_passes = 0\n",
    "  for images, labels in train_dataset:\n",
    "      labels_np = labels.numpy()\n",
    "      passes = np.count_nonzero(labels_np)\n",
    "      num_passes = num_passes + passes\n",
    "      fails = len(labels_np) - passes\n",
    "      num_fails = num_fails + fails\n",
    "      \n",
    "  total = num_fails + num_passes\n",
    "  print('Train Examples:\\n    Total: {}\\n, Passes: {}, Fails: {} ({:.2f}% of total)\\n'.format(\n",
    "      total, num_passes, num_fails, 100 * num_fails / total))\n",
    "\n",
    "  # Class weights\n",
    "  weight_for_fail = (1 / num_fails) * (total / 2.0)\n",
    "  weight_for_passes = (1 / num_passes) * (total / 2.0)\n",
    "\n",
    "  class_weights = {0: weight_for_fail, 1: weight_for_passes}\n",
    "\n",
    "  print('Weight for class 0 (Fail): {:.2f}'.format(weight_for_fail))\n",
    "  print('Weight for class 1 (Pass): {:.2f}'.format(weight_for_passes))\n",
    "\n",
    "  # Number of validation classes\n",
    "  num_fails = 0\n",
    "  num_passes = 0\n",
    "  for images, labels in validation_dataset:\n",
    "    labels_np = labels.numpy()\n",
    "    passes = np.count_nonzero(labels_np)\n",
    "    num_passes = num_passes + passes\n",
    "    fails = len(labels_np) - passes\n",
    "    num_fails = num_fails + fails\n",
    "    \n",
    "  total = num_fails + num_passes\n",
    "  print('Validation Examples: Total: {}\\n, Passes: {}, Fails: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, num_passes, num_fails, 100 * num_fails / total))\n",
    "  \n",
    "  return class_weights\n",
    "\n",
    "def compute_weights_scipy(train_dataset):\n",
    "  num_fails = 0\n",
    "  num_passes = 0\n",
    "  concat_labels = []\n",
    "  for images, labels in train_dataset:\n",
    "      labels_np = labels.numpy()\n",
    "      concat_labels.extend(list(labels_np))\n",
    "      passes = np.count_nonzero(labels_np)\n",
    "      num_passes = num_passes + passes\n",
    "      fails = len(labels_np) - passes\n",
    "      num_fails = num_fails + fails\n",
    "    \n",
    "  print(concat_labels)\n",
    "  class_weights = class_weight.compute_class_weight(class_weight ='balanced',\n",
    "                                                     classes = np.unique(concat_labels),\n",
    "                                                     y = concat_labels)\n",
    "  print(\"Class weights (SCIPY): \" + str(class_weights))\n",
    "  return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baccf9b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "def get_model(training=True, base_learning_rate = 0.0001, IMG_SIZE = (224, 224), model_type = model_type):\n",
    "    IMG_SHAPE = IMG_SIZE + (3,)\n",
    "\n",
    "    ## Densenet, convnext, resnet50\n",
    "\n",
    "    base_model_trainable = True\n",
    "\n",
    "    if model_type != \"custom\":\n",
    "        if model_type == \"mobilenet\":\n",
    "            ## MOBILENETV2\n",
    "            base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                                          include_top=False,\n",
    "                                                          weights='imagenet')\n",
    "            preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "            fine_tune_at = 154 - 15\n",
    "        elif model_type == \"resnet\":\n",
    "            ## RESNET50\n",
    "            base_model = tf.keras.applications.resnet50.ResNet50(input_shape=IMG_SHAPE,\n",
    "                                                          include_top=False,\n",
    "                                                        weights='imagenet')\n",
    "            preprocess_input = tf.keras.applications.resnet50.preprocess_input\n",
    "            fine_tune_at = 175 \n",
    "        \n",
    "        elif model_type == \"densenet\":\n",
    "            print(\"DENSENET SELECTED\")\n",
    "            ## Densenet\n",
    "            base_model = tf.keras.applications.densenet.DenseNet121(input_shape=IMG_SHAPE,\n",
    "                                                          include_top=False,\n",
    "                                                        weights='imagenet')\n",
    "            preprocess_input = tf.keras.applications.densenet.preprocess_input\n",
    "            fine_tune_at = 427 - 20 \n",
    "        elif model_type == \"densenet with dropout\":\n",
    "            ## Densenet\n",
    "            base_model = DenseNetWithDropout(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "            preprocess_input = tf.keras.applications.densenet.preprocess_input\n",
    "            fine_tune_at = 300\n",
    "        elif model_type == \"vgg16\":\n",
    "            ## Vgg16\n",
    "            base_model = tf.keras.applications.vgg16.VGG16(input_shape=IMG_SHAPE,\n",
    "                                                        include_top=False,\n",
    "                                                      weights='imagenet')\n",
    "            preprocess_input = tf.keras.applications.vgg16.preprocess_input\n",
    "        elif model_type == \"convnexttiny\":\n",
    "            print(\"CONVNEXT SELECTED\")\n",
    "            # convnexttiny\n",
    "            base_model = ConvNeXtTiny(input_shape=IMG_SHAPE,\n",
    "                                      include_top=False,\n",
    "                                      weights='imagenet')\n",
    "            preprocess_input = tf.keras.applications.convnext.preprocess_input\n",
    "            fine_tune_at = 132 #126 #was 132\n",
    "            \n",
    "        print(\"Number of layers = \" + str(len(base_model.layers)))\n",
    "        \n",
    "        if base_model_trainable:\n",
    "            base_model.trainable = True\n",
    "            base_learning_rate = base_learning_rate/10\n",
    "\n",
    "        \n",
    "            # Fine-tune from this layer onwards \n",
    "            print(\"Number of layers = \" + str(len(base_model.layers)))\n",
    "        \n",
    "            # Freeze all the layers before the `fine_tune_at` layer\n",
    "            for layer in base_model.layers[:fine_tune_at]:\n",
    "                layer.trainable = False\n",
    "        else:\n",
    "             base_model.trainable = False      \n",
    "    \n",
    "\n",
    "        global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        prediction_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "        inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "        x = preprocess_input(inputs)\n",
    "        x = base_model(x) #was training=False\n",
    "        x = global_average_layer(x)\n",
    "        x = tf.keras.layers.Dropout(0.8)(x, training=training)\n",
    "        outputs = prediction_layer(x)\n",
    "        model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "    elif model_type == \"custom\":\n",
    "        model = tf.keras.Sequential([\n",
    "          tf.keras.layers.Rescaling(1./255),\n",
    "          tf.keras.layers.Conv2D(12, 3, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "          tf.keras.layers.MaxPooling2D(),\n",
    "          tf.keras.layers.Conv2D(24, 3, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "          tf.keras.layers.MaxPooling2D(),\n",
    "          tf.keras.layers.Conv2D(48, 3, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "          tf.keras.layers.MaxPooling2D(),\n",
    "          tf.keras.layers.Flatten(),\n",
    "          tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "          tf.keras.layers.Dropout(0.6),\n",
    "          tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy']) # recent change - added weight decay, subsequently removed , weight_decay=0.0005\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbecfbc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_test_model(model_type):\n",
    "  test_model = get_model(training=False, model_type=model_type)\n",
    "  test_model.load_weights(\"Weights/\" + model_type + \".h5\")\n",
    "\n",
    "  return test_model\n",
    "\n",
    "def get_performance(model, test_dataset):\n",
    "  loss, accuracy = model.evaluate(test_dataset)\n",
    "  print('Test accuracy :', accuracy)\n",
    "  return accuracy\n",
    "\n",
    "def predict_on_dataset(model, dataset):\n",
    "    labels = []\n",
    "    predictions = []\n",
    "\n",
    "    for images, image_labels in dataset:\n",
    "        preds = model.predict(images)\n",
    "        predictions.extend(preds)\n",
    "        labels.extend(image_labels.numpy())\n",
    "\n",
    "    return np.array(labels).flatten(), np.array(predictions).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ae32d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plotting functions\n",
    "def plot_image_classifications(validation_dataset):\n",
    "  class_names = [\"Fail\", \"Pass\"]\n",
    "\n",
    "  image_batch, label_batch = validation_dataset.as_numpy_iterator().next()\n",
    "  predictions = model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "  # Apply a sigmoid since our model returns logits\n",
    "  predictions = tf.nn.sigmoid(predictions)\n",
    "  predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "  print('Predictions:\\n', predictions.numpy())\n",
    "  print('Labels:\\n', label_batch)\n",
    "  print(predictions.numpy() - label_batch)\n",
    "\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  start = 0\n",
    "  stop = 10\n",
    "  for i in range(start,stop):\n",
    "    ax = plt.subplot(4, 5, i - start + 1)\n",
    "    plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "    plt.title(\"True: \" + class_names[label_batch[i]] + '\\n' + \"Pred: \" + class_names[predictions[i]])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "\n",
    "def calculate_metrics(labels, predicted_classes, class_of_interest=0):\n",
    "\n",
    "    # Get confusion matrix\n",
    "    cm = confusion_matrix(labels, predicted_classes)\n",
    "\n",
    "    # Get values for class of interest\n",
    "    TP = cm[class_of_interest, class_of_interest]\n",
    "    FP = np.sum(cm[:, class_of_interest]) - TP\n",
    "    FN = np.sum(cm[class_of_interest, :]) - TP\n",
    "    TN = np.sum(cm) - TP - FP - FN\n",
    "\n",
    "    # Calculate metrics\n",
    "    sensitivity = TP / (TP + FN)\n",
    "    specificity = TN / (TN + FP)\n",
    "    precision = precision_score(labels, predicted_classes, pos_label=class_of_interest)\n",
    "    recall = recall_score(labels, predicted_classes, pos_label=class_of_interest)\n",
    "\n",
    "    print(\"Sensitivity = \" + str(sensitivity))\n",
    "    print(\"Specificity = \" + str(specificity))\n",
    "    print(\"Precision = \" + str(precision))\n",
    "    print(\"Recall = \" + str(recall))\n",
    "\n",
    "    return sensitivity, specificity, precision, recall\n",
    "    \n",
    "def plot_confusion_matrix(label_batch, predictions, class_names, save_path):\n",
    "  predictions = tf.convert_to_tensor(predictions, dtype=tf.float32) # Convert to tensor  \n",
    "  predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "  cm = confusion_matrix(label_batch, predictions.numpy() , normalize='true')\n",
    "  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "  disp.plot()\n",
    "  plt.savefig(save_path, facecolor='white', dpi=300,\n",
    "              transparent=False)\n",
    "  plt.show()\n",
    "  plt.close('all')\n",
    "\n",
    "def plot_roc(label_batch, predictions, save_path):\n",
    "  fp, tp, _ = roc_curve(label_batch, predictions)\n",
    "\n",
    "  plt.plot(100*fp, 100*tp, label=\"ROC\", linewidth=2)\n",
    "  plt.xlabel('False positives [%]')\n",
    "  plt.ylabel('True positives [%]')\n",
    "  plt.xlim([-0.5,100])\n",
    "  plt.ylim([0,100.5])\n",
    "  plt.grid(True)\n",
    "  ax = plt.gca()\n",
    "  ax.set_aspect('equal')\n",
    "  plt.savefig(save_path, facecolor='white', dpi=300,\n",
    "              transparent=False)\n",
    "  plt.show()\n",
    "  plt.close('all')\n",
    "\n",
    "def get_performance_metrics(labels, predictions):\n",
    "  auc = roc_auc_score(labels, predictions)\n",
    "  predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "  print('Auc: %.3f' % auc)\n",
    "  precision = precision_score(labels, predictions, pos_label=0, average='binary')\n",
    "  recall = recall_score(labels, predictions, pos_label=0, average='binary')\n",
    "  f1 = f1_score(labels, predictions, pos_label=0, average='binary')\n",
    "  print('Precision: %.3f, Recall: %.3f, F-Score: %.3f,' % (precision, recall, f1))\n",
    "  print(classification_report(labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9be6777-f1ea-48a2-9729-08654f700d23",
   "metadata": {},
   "source": [
    "# Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d35fdf-e3e0-467b-8d5a-4194dc1bef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate scheduler\n",
    "def scheduler(epoch, lr):\n",
    "  if epoch < (50 if model_type is 'densenet' else 25): # convnext: 25, densenet: 40, resnet: 15\n",
    "    return lr\n",
    "  else:\n",
    "    return lr * tf.math.exp(-0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75df2bb-ea09-4b7a-8ee2-c369c51dc393",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# top_dir =  \"Data/Chronological Fold May 3/\"\n",
    "top_dir = \"../Audio Data/Data/\"\n",
    "folds = sorted(glob.glob(top_dir + \"/*\"))\n",
    "num_folds = len(folds)\n",
    "print(\"Num folds = \" + str(num_folds))\n",
    "results = []\n",
    "validation_subject = []\n",
    "epochs =  55 if model_type is 'densenet' else 30 \n",
    "class_names = [\"Fail\", \"Pass\"]\n",
    "\n",
    "\n",
    "concat_predictions = []\n",
    "concat_predict_score_mean = []\n",
    "fold_labels = []\n",
    "prob_avg = []\n",
    "start_tic = time.time()\n",
    "first_pass = True\n",
    "for fold in folds:\n",
    "  tic = time.time()\n",
    "  training_dir = fold + \"/Train/\"\n",
    "  test_dir = fold + \"/Validation/\"\n",
    "  print(training_dir)\n",
    "\n",
    "  train_dataset, validation_dataset, test_dataset = load_data(training_dir, None)\n",
    "  model = get_model(training=True)\n",
    "\n",
    "  weights = compute_weights(train_dataset, validation_dataset)\n",
    "\n",
    "  # Early stopping and model checkpointing\n",
    "  early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=True)\n",
    "  #model_checkpoint = ModelCheckpoint('best_model.model', monitor='loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "  lr_scheduler_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "  history = model.fit(train_dataset,\n",
    "                    epochs=epochs,\n",
    "                     validation_data=validation_dataset,\n",
    "                    callbacks=[early_stopping, lr_scheduler_callback], class_weight=weights)\n",
    " \n",
    "  results = get_performance(model, train_dataset)\n",
    "\n",
    "  if first_pass:\n",
    "    print(model.summary())\n",
    "    first_pass = False\n",
    "      \n",
    "print(results)\n",
    "print(\"Total elapsed time is \" + str(time.time() - start_tic))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3268f4-fef4-4a61-a7ec-3af88ece3ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "  plot_accuracy_and_loss(history)\n",
    "  plot_accuracy_and_loss_plotly(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7af96e2-2ff9-4933-ba6b-77106a35c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, predictions = predict_on_dataset(model, train_dataset)\n",
    "plot_roc(labels, predictions,  \"Result Images/train_clip_roc.png\")\n",
    "get_performance_metrics(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbbf52b-a2bb-48dd-a987-4cf66ca34044",
   "metadata": {},
   "source": [
    "# Save Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbad0b29-571b-4129-b2f5-f3216de498b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('Weights/' + model_type + '.h5' , overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fe5df1-ca02-4cfd-9efd-b5a057070d12",
   "metadata": {},
   "source": [
    "# Run on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92858e8-71fb-48cf-9d63-528d5d8827d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rootdir = top_dir + \"Fold 0/Test/\"\n",
    "results = []\n",
    "participant_labels = []\n",
    "participant_predictions = []\n",
    "concat_labels = []\n",
    "tic = time.time()\n",
    "\n",
    "test_model = get_model(training=False)\n",
    "test_model.load_weights(\"Weights/\" + model_type + \".h5\")\n",
    "\n",
    "\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for dir in dirs:\n",
    "        print(rootdir + dir)\n",
    "        _, _, test_dataset = load_data(None, rootdir + dir)\n",
    "        corrected_labels, corrected_predictions = predict_on_dataset(test_model, test_dataset)\n",
    "    \n",
    "        concat_labels = np.concatenate((concat_labels, corrected_labels), axis=0)\n",
    "        concat_predictions = np.concatenate((concat_predictions, corrected_predictions), axis=0)\n",
    "        predict_on_performance = 1-(np.count_nonzero(tf.where(corrected_predictions < 0.5, 0, 1) - corrected_labels))/len(corrected_labels)\n",
    "        predict_score_mean = np.mean(corrected_predictions)\n",
    "        concat_predict_score_mean.append(predict_score_mean)\n",
    "        \n",
    "\n",
    "        print(\"Labels \" + str(corrected_labels))\n",
    "        print(\"Predictions = \" + str(tf.where(corrected_predictions < 0.5, 0, 1).numpy()))\n",
    "        print(\"Label length = \" + str(len(corrected_labels)))\n",
    "        print(\"Predictions length = \" + str(len(corrected_predictions)))\n",
    "        print(\"Model performance (predict_on) \" + str(predict_on_performance))\n",
    "        #print(corrected_predictions)\n",
    "        print(\"Prediction cumulative score = \" + str(predict_score_mean))\n",
    "        get_performance(model, test_dataset)\n",
    "        results.append(predict_on_performance)\n",
    "        prob_avg.append(np.mean(corrected_predictions))\n",
    "        \n",
    "        participant_labels.append(corrected_labels[0])\n",
    "        participant_predictions.append(0 if predict_on_performance < 0.5 else 1)\n",
    "\n",
    "        print(\"Elapsed time = \" + str(time.time() - tic))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec960c0-c779-4c2c-abf6-60220d8f2967",
   "metadata": {},
   "source": [
    "## Single Clip Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0442db4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib inline\n",
    "result_dict = []\n",
    "i = 0\n",
    "#print(folds)\n",
    "for fold in folds:\n",
    "  result_dict.append({\"Fold\": fold, \"Accuracy\": results[i]})\n",
    "  i = i + 1\n",
    "#print((prob_avg))\n",
    "\n",
    "print(\"Overall accuracy is \" + str(np.mean(results)))\n",
    "plot_confusion_matrix(concat_labels, concat_predictions, class_names, \"Result Images/clip_confusion.png\")\n",
    "plot_roc(concat_labels, concat_predictions,  \"Result Images/clip_roc.png\")\n",
    "get_performance_metrics(concat_labels, concat_predictions)\n",
    "predicted_labels = tf.where(concat_predictions < 0.5, 0, 1)\n",
    "calculate_metrics(concat_labels, predicted_labels, class_of_interest=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bce1d4d-0b2d-4195-a012-24eed4800f09",
   "metadata": {},
   "source": [
    "# Participant Level Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d2ddeb-a895-43a1-8e54-f75f5b99b589",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "participant_predictions = []\n",
    "\n",
    "for score in concat_predict_score_mean: # can also use prob_avg\n",
    "    participant_predictions.append(1 if score > 0.5 else 0)\n",
    "    i=i+1\n",
    "\n",
    "\n",
    "plot_confusion_matrix(np.array(participant_labels), np.array(participant_predictions), class_names, \"Result Images/participant_confusion.png\")\n",
    "\n",
    "print(concat_predict_score_mean)\n",
    "print(participant_labels)\n",
    "print(participant_predictions)\n",
    "plot_roc(participant_labels, participant_predictions,  \"Result Images/participant_roc.png\")\n",
    "get_performance_metrics(participant_labels, np.array(concat_predict_score_mean))\n",
    "predicted_participant_labels = tf.where( np.array(concat_predict_score_mean) < 0.5, 0, 1)\n",
    "calculate_metrics(participant_labels, predicted_participant_labels, class_of_interest=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa34aa2",
   "metadata": {},
   "source": [
    "# **Dummy Classifier to compare performance**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aa56cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dummy_clf = DummyClassifier(strategy=\"constant\", constant=1)\n",
    "dummy_clf.fit(None, concat_labels)\n",
    "dummy_predictions = dummy_clf.predict(np.ones((len(concat_labels),1)))\n",
    "get_performance_metrics(concat_labels, dummy_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
