{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c0c27b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import shutil\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "\n",
    "import math\n",
    "import glob\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from PIL import Image\n",
    "from tqdm import tqdm,tnrange,tqdm_notebook\n",
    "import tensorflow as tf\n",
    "from tqdm.keras import TqdmCallback\n",
    "from tensorflow.keras import backend as K \n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras import applications as app\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten,AveragePooling2D#, CenterCrop\n",
    "from tensorflow.keras.layers.experimental.preprocessing import CenterCrop\n",
    "from tensorflow.keras.layers import Dense,BatchNormalization,Dropout \n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.applications import EfficientNetB4, ResNet50, ResNet101, VGG16, MobileNet, InceptionV3, EfficientNetB2, densenet, ConvNeXtTiny\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "%matplotlib inline\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d225229f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Helper functions (run me)\n",
    "\n",
    "def set_device():\n",
    "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "  if device != \"cuda\":\n",
    "      print(\"WARNING: For this notebook to perform best, \"\n",
    "          \"if possible, in the menu under `Runtime` -> \"\n",
    "          \"`Change runtime type.`  select `GPU` \")\n",
    "  else:\n",
    "      print(\"GPU is enabled in this notebook.\")\n",
    "\n",
    "  return device\n",
    "\n",
    "def set_device_tf():    \n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "      # Restrict TensorFlow to only use the first GPU\n",
    "      try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        print(gpus[0])\n",
    "      except RuntimeError as e:\n",
    "        # Visible devices must be set at program startup\n",
    "        print(e)\n",
    "    else:\n",
    "      print(\"No GPUs found\")\n",
    "\n",
    "#  Plotting function.\n",
    "def plot_accuracy_and_loss(history):\n",
    "  acc = history.history['accuracy']\n",
    "  val_acc = history.history['val_accuracy']\n",
    "\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  plt.figure(figsize=(8, 8))\n",
    "  plt.subplot(2, 1, 1)\n",
    "  plt.plot(acc, label='Training')\n",
    "  plt.plot(val_acc, label='Validation')\n",
    "  plt.legend(loc='lower right')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.ylim([min(plt.ylim()),1.05])\n",
    "  plt.title('Training and Validation Accuracy')\n",
    "\n",
    "  plt.subplot(2, 1, 2)\n",
    "  plt.plot(loss, label='Training')\n",
    "  plt.plot(val_loss, label='Validation')\n",
    "  plt.legend(loc='upper right')\n",
    "  plt.ylabel('Cross Entropy')\n",
    "  plt.ylim([np.min(np.concatenate((val_loss,loss)))-0.1,np.max(np.concatenate((val_loss,loss)))+0.1])\n",
    "  plt.title('Training and Validation Loss')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.show()\n",
    "  plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0eb01a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_device_tf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d4903b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data loading.\n",
    "def load_data(train_dir, test_dir):\n",
    "  BATCH_SIZE = 32 # 64 can fill up GPU memory!\n",
    "  IMG_SIZE = (224, 224)\n",
    "  AUTOTUNE = tf.data.AUTOTUNE\n",
    "    \n",
    "  if train_dir is not None:\n",
    "    train_dataset = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
    "                                                                  shuffle=True,\n",
    "                                                                  validation_split=.2, ##RECENT CHANGE\n",
    "                                                                  seed=123,\n",
    "                                                                  subset='training',\n",
    "                                                                  batch_size=BATCH_SIZE,\n",
    "                                                                  image_size=IMG_SIZE)\n",
    "\n",
    "    validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
    "                                                                  shuffle=True,\n",
    "                                                                  validation_split=.2, ##RECENT CHANGE\n",
    "                                                                  seed=123,\n",
    "                                                                  subset='validation',\n",
    "                                                                  batch_size=BATCH_SIZE,\n",
    "                                                                  image_size=IMG_SIZE)\n",
    "    train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    print('Number of train batches: %d' % tf.data.experimental.cardinality(train_dataset))\n",
    "  else:\n",
    "    train_dataset = None\n",
    "    validation_dataset = None\n",
    "        \n",
    "  if test_dir is not None:\n",
    "    test_dataset = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
    "                                                                  shuffle=False,\n",
    "                                                                  image_size=IMG_SIZE)\n",
    "    test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "  else:\n",
    "    test_dataset = None\n",
    "\n",
    "  return train_dataset, validation_dataset, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ea8cb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_weights(train_dataset, validation_dataset):\n",
    "  num_fails = 0\n",
    "  num_passes = 0\n",
    "  for images, labels in train_dataset:\n",
    "      labels_np = labels.numpy()\n",
    "      passes = np.count_nonzero(labels_np)\n",
    "      num_passes = num_passes + passes\n",
    "      fails = len(labels_np) - passes\n",
    "      num_fails = num_fails + fails\n",
    "      \n",
    "  total = num_fails + num_passes\n",
    "  print('Train Examples:\\n    Total: {}\\n, Passes: {}, Fails: {} ({:.2f}% of total)\\n'.format(\n",
    "      total, num_passes, num_fails, 100 * num_fails / total))\n",
    "\n",
    "  # Class weights\n",
    "  weight_for_fail = (1 / num_fails) * (total / 2.0)\n",
    "  weight_for_passes = (1 / num_passes) * (total / 2.0)\n",
    "\n",
    "  class_weights = {0: weight_for_fail, 1: weight_for_passes}\n",
    "\n",
    "  print('Weight for class 0 (Fail): {:.2f}'.format(weight_for_fail))\n",
    "  print('Weight for class 1 (Pass): {:.2f}'.format(weight_for_passes))\n",
    "\n",
    "  # Number of validation classes\n",
    "  num_fails = 0\n",
    "  num_passes = 0\n",
    "  for images, labels in validation_dataset:\n",
    "    labels_np = labels.numpy()\n",
    "    passes = np.count_nonzero(labels_np)\n",
    "    num_passes = num_passes + passes\n",
    "    fails = len(labels_np) - passes\n",
    "    num_fails = num_fails + fails\n",
    "    \n",
    "  total = num_fails + num_passes\n",
    "  print('Validation Examples: Total: {}\\n, Passes: {}, Fails: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, num_passes, num_fails, 100 * num_fails / total))\n",
    "  \n",
    "  return class_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baccf9b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "def get_model(training=False, base_learning_rate = 0.0001, IMG_SIZE = (224, 224), model_type = ''):\n",
    "    IMG_SHAPE = IMG_SIZE + (3,)\n",
    "\n",
    "    ## Densenet, convnext, resnet50\n",
    "\n",
    "    base_model_trainable = True\n",
    "\n",
    "    if model_type != \"custom\":\n",
    "        if model_type == \"mobilenet\":\n",
    "            ## MOBILENETV2\n",
    "            base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                                          include_top=False,\n",
    "                                                          weights='imagenet')\n",
    "            preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "        elif model_type == \"resnet\":\n",
    "            ## RESNET50\n",
    "            base_model = tf.keras.applications.resnet50.ResNet50(input_shape=IMG_SHAPE,\n",
    "                                                          include_top=False,\n",
    "                                                        weights='imagenet')\n",
    "            preprocess_input = tf.keras.applications.resnet50.preprocess_input\n",
    "            fine_tune_at = 175 - 19\n",
    "        \n",
    "        elif model_type == \"densenet\":\n",
    "            ## Densenet\n",
    "            base_model = tf.keras.applications.densenet.DenseNet121(input_shape=IMG_SHAPE,\n",
    "                                                          include_top=False,\n",
    "                                                        weights='imagenet')\n",
    "            preprocess_input = tf.keras.applications.densenet.preprocess_input\n",
    "            fine_tune_at = 427 - 20 #52 #427- 35 #427 - 20\n",
    "        elif model_type == \"densenet with dropout\":\n",
    "            ## Densenet\n",
    "            base_model = DenseNetWithDropout(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "            preprocess_input = tf.keras.applications.densenet.preprocess_input\n",
    "            fine_tune_at = 300\n",
    "        elif model_type == \"vgg16\":\n",
    "            ## Vgg16\n",
    "            base_model = tf.keras.applications.vgg16.VGG16(input_shape=IMG_SHAPE,\n",
    "                                                        include_top=False,\n",
    "                                                      weights='imagenet')\n",
    "            preprocess_input = tf.keras.applications.vgg16.preprocess_input\n",
    "        elif model_type == \"convnexttiny\":\n",
    "            print(\"CONVNEXT SELECTED\")\n",
    "            # convnexttiny\n",
    "            base_model = ConvNeXtTiny(input_shape=IMG_SHAPE,\n",
    "                                      include_top=False,\n",
    "                                      weights='imagenet')\n",
    "            preprocess_input = tf.keras.applications.convnext.preprocess_input\n",
    "            fine_tune_at = 132 #132 #was 132\n",
    "\n",
    "\n",
    "        #image_batch, label_batch = next(iter(train_dataset))\n",
    "        #feature_batch = base_model(image_batch)\n",
    "        print(\"Number of layers = \" + str(len(base_model.layers)))\n",
    "        \n",
    "       \n",
    "        if base_model_trainable:\n",
    "            base_model.trainable = True\n",
    "            base_learning_rate = base_learning_rate/10\n",
    "        \n",
    "            # Fine-tune from this layer onwards \n",
    "            print(\"Number of layers = \" + str(len(base_model.layers)))\n",
    "\n",
    "            # Freeze all the layers before the `fine_tune_at` layer\n",
    "            for layer in base_model.layers[:fine_tune_at]:\n",
    "                layer.trainable = False\n",
    "        else:\n",
    "             base_model.trainable = False\n",
    "    \n",
    "\n",
    "        global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        prediction_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "        inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "        x = preprocess_input(inputs)\n",
    "        x = base_model(x, training=False) #was training=False\n",
    "        x = global_average_layer(x)\n",
    "        x = tf.keras.layers.Dropout(0.8)(x, training=training)\n",
    "        outputs = prediction_layer(x)\n",
    "        model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "    elif model_type == \"custom\":\n",
    "        model = tf.keras.Sequential([\n",
    "          tf.keras.layers.Rescaling(1./255),\n",
    "          tf.keras.layers.Conv2D(12, 3, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "          tf.keras.layers.MaxPooling2D(),\n",
    "          tf.keras.layers.Conv2D(24, 3, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "          tf.keras.layers.MaxPooling2D(),\n",
    "          tf.keras.layers.Conv2D(48, 3, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "          tf.keras.layers.MaxPooling2D(),\n",
    "          tf.keras.layers.Flatten(),\n",
    "          tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "          tf.keras.layers.Dropout(0.6),\n",
    "          tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy']) # recent change - added weight decay, subsequently removed , weight_decay=0.0005\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbecfbc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_test_model(model_type):\n",
    "  test_model = get_model(training=False, model_type=model_type)\n",
    "  test_model.load_weights(\"Weights/\" + model_type + \".h5\")\n",
    "\n",
    "  return test_model\n",
    "\n",
    "def get_performance(model, test_dataset):\n",
    "  test_model = get_test_model(model)\n",
    "  loss, accuracy = test_model.evaluate(test_dataset)\n",
    "  print('Test accuracy :', accuracy)\n",
    "  return accuracy\n",
    "\n",
    "def predict_on_dataset(model, dataset):\n",
    "    labels = []\n",
    "    predictions = []\n",
    "\n",
    "    for images, image_labels in dataset:\n",
    "        preds = model.predict(images)\n",
    "        predictions.extend(preds)\n",
    "        labels.extend(image_labels.numpy())\n",
    "\n",
    "    return np.array(labels).flatten(), np.array(predictions).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ae32d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plotting functions\n",
    "def plot_image_classifications(validation_dataset):\n",
    "  class_names = [\"Fail\", \"Pass\"]\n",
    "\n",
    "  image_batch, label_batch = validation_dataset.as_numpy_iterator().next()\n",
    "  predictions = model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "  # Apply a sigmoid since our model returns logits\n",
    "  predictions = tf.nn.sigmoid(predictions)\n",
    "  predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "  print('Predictions:\\n', predictions.numpy())\n",
    "  print('Labels:\\n', label_batch)\n",
    "  print(predictions.numpy() - label_batch)\n",
    "\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  start = 0\n",
    "  stop = 10\n",
    "  for i in range(start,stop):\n",
    "    ax = plt.subplot(4, 5, i - start + 1)\n",
    "    plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "    plt.title(\"True: \" + class_names[label_batch[i]] + '\\n' + \"Pred: \" + class_names[predictions[i]])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "\n",
    "def calculate_metrics(labels, predicted_classes, class_of_interest=0):\n",
    "\n",
    "    # Get confusion matrix\n",
    "    cm = confusion_matrix(labels, predicted_classes)\n",
    "\n",
    "    # Get values for class of interest\n",
    "    TP = cm[class_of_interest, class_of_interest]\n",
    "    FP = np.sum(cm[:, class_of_interest]) - TP\n",
    "    FN = np.sum(cm[class_of_interest, :]) - TP\n",
    "    TN = np.sum(cm) - TP - FP - FN\n",
    "\n",
    "    # Calculate metrics\n",
    "    sensitivity = TP / (TP + FN)\n",
    "    specificity = TN / (TN + FP)\n",
    "    precision = precision_score(labels, predicted_classes, pos_label=class_of_interest)\n",
    "    recall = recall_score(labels, predicted_classes, pos_label=class_of_interest)\n",
    "\n",
    "    print(\"Sensitivity = \" + str(sensitivity))\n",
    "    print(\"Specificity = \" + str(specificity))\n",
    "    print(\"Precision = \" + str(precision))\n",
    "    print(\"Recall = \" + str(recall))\n",
    "\n",
    "    return sensitivity, specificity, precision, recall\n",
    "\n",
    "def plot_confusion_matrix_plotly(label_batch, predictions, class_names, save_path):\n",
    "    predictions = tf.convert_to_tensor(predictions, dtype=tf.float32)  # Convert to tensor  \n",
    "    predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "    cm = confusion_matrix(label_batch, predictions.numpy(), normalize='true')\n",
    "    \n",
    "    # Convert normalized values to percentage and prepare text annotations\n",
    "    annotations = [f'{value:.1%}' for value in cm.flatten()]\n",
    "    annotations = np.array(annotations).reshape(cm.shape)\n",
    "    \n",
    "    # Prepare text annotation colors\n",
    "    text_colors = [['white', 'black'], ['black', 'white']]  # Top left and bottom right are white\n",
    "    \n",
    "    # Create heatmap\n",
    "    heatmap = go.Heatmap(z=cm,\n",
    "                         x=class_names,\n",
    "                         y=class_names,\n",
    "                         colorscale='Blues',\n",
    "                         zmin=0,\n",
    "                         zmax=1)\n",
    "    \n",
    "    # Create text annotations\n",
    "    text_annotations = go.Scatter(x=np.tile(class_names, len(class_names)),\n",
    "                                  y=np.repeat(class_names, len(class_names)),\n",
    "                                  text=annotations.flatten(),\n",
    "                                  mode='text',\n",
    "                                  textposition='middle center',\n",
    "                                  textfont_color=np.array(text_colors).flatten())\n",
    "    \n",
    "    # Create figure\n",
    "    fig = go.Figure(data=[heatmap, text_annotations])\n",
    "    fig.update_layout(title='Confusion Matrix',\n",
    "                      xaxis_title='Predicted Label',\n",
    "                      yaxis_title='True Label',\n",
    "                      yaxis_autorange='reversed',\n",
    "                      width=600,  # Set width\n",
    "                      height=600,  # Set height\n",
    "                      margin=dict(t=50, b=50, l=50, r=50))  # Adjust margins to better center the plot\n",
    "    \n",
    "    fig.show()\n",
    "    pio.write_image(fig, save_path, scale=2)  # Use scale parameter to increase resolution\n",
    "\n",
    "def plot_confusion_matrix_plotly_no_normalize(label_batch, predictions, class_names, save_path):\n",
    "    predictions = tf.convert_to_tensor(predictions, dtype=tf.float32)  # Convert to tensor  \n",
    "    predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "    cm = confusion_matrix(label_batch, predictions.numpy())  # Removed normalization\n",
    "    \n",
    "    # Prepare text annotations\n",
    "    annotations = cm.astype(str)  # Convert counts to string\n",
    "    annotations = np.array(annotations).reshape(cm.shape)\n",
    "    \n",
    "    # Prepare text annotation colors\n",
    "    text_colors = [['white', 'black'], ['black', 'white']]  # Top left and bottom right are white\n",
    "    \n",
    "    # Create heatmap\n",
    "    heatmap = go.Heatmap(z=cm,\n",
    "                         x=class_names,\n",
    "                         y=class_names,\n",
    "                         colorscale='Blues')\n",
    "    \n",
    "    # Create text annotations\n",
    "    text_annotations = go.Scatter(x=np.tile(class_names, len(class_names)),\n",
    "                                  y=np.repeat(class_names, len(class_names)),\n",
    "                                  text=annotations.flatten(),\n",
    "                                  mode='text',\n",
    "                                  textposition='middle center',\n",
    "                                  textfont_color=np.array(text_colors).flatten())\n",
    "    \n",
    "    # Create figure\n",
    "    fig = go.Figure(data=[heatmap, text_annotations])\n",
    "    fig.update_layout(title='Confusion Matrix',\n",
    "                      xaxis_title='Predicted',\n",
    "                      yaxis_title='Actual',\n",
    "                      yaxis_autorange='reversed',\n",
    "                      width=600,  # Set width\n",
    "                      height=600,  # Set height\n",
    "                      margin=dict(t=50, b=50, l=50, r=50))  # Adjust margins to better center the plot\n",
    "    \n",
    "    fig.show()\n",
    "    pio.write_image(fig, save_path, scale=2)  # Use scale parameter to increase resolution\n",
    "\n",
    "    \n",
    "def plot_confusion_matrix(label_batch, predictions, class_names, save_path):\n",
    "  predictions = tf.convert_to_tensor(predictions, dtype=tf.float32) # Convert to tensor  \n",
    "  predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "  cm = confusion_matrix(label_batch, predictions.numpy() , normalize='true')\n",
    "  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "  disp.plot()\n",
    "  plt.savefig(save_path, facecolor='white', dpi=300,\n",
    "              transparent=False)\n",
    "  plt.show()\n",
    "  plt.close('all')\n",
    "\n",
    "def plot_roc(label_batch, predictions, save_path):\n",
    "  fp, tp, _ = roc_curve(label_batch, predictions)\n",
    "\n",
    "  plt.plot(100*fp, 100*tp, label=\"ROC\", linewidth=2)\n",
    "  plt.xlabel('False positives [%]')\n",
    "  plt.ylabel('True positives [%]')\n",
    "  plt.xlim([-0.5,100])\n",
    "  plt.ylim([0,100.5])\n",
    "  plt.grid(True)\n",
    "  ax = plt.gca()\n",
    "  ax.set_aspect('equal')\n",
    "  #plt.savefig(save_path + 'roc.png', facecolor='white', dpi=300,\n",
    "  #            transparent=False)\n",
    "  plt.show()\n",
    "  plt.close('all')\n",
    "\n",
    "def get_performance_metrics(labels, predictions):\n",
    "  auc = roc_auc_score(labels, predictions)\n",
    "  predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "  print('Auc: %.3f' % auc)\n",
    "  precision = precision_score(labels, predictions, pos_label=0, average='binary')\n",
    "  recall = recall_score(labels, predictions, pos_label=0, average='binary')\n",
    "  f1 = f1_score(labels, predictions, pos_label=0, average='binary')\n",
    "  print('Precision: %.3f, Recall: %.3f, F-Score: %.3f,' % (precision, recall, f1))\n",
    "  print(classification_report(labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92858e8-71fb-48cf-9d63-528d5d8827d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "densenet_model = get_test_model('densenet')\n",
    "convnexttiny_model = get_test_model('convnexttiny') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5ef651-88aa-40f4-af34-24074f502fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_dir = \"../Audio Data/Data/\"\n",
    "rootdir = top_dir + \"Fold 0/Test/\"\n",
    "results = []\n",
    "participant_labels = []\n",
    "participant_predictions = []\n",
    "concat_labels = []\n",
    "concat_predictions = []\n",
    "concat_predict_score_mean = []\n",
    "fold_labels = []\n",
    "prob_avg = []\n",
    "output_avg = []\n",
    "tic = time.time()\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for dir in dirs:\n",
    "        print(rootdir + dir)\n",
    "        _, _, test_dataset = load_data(None, rootdir + dir)\n",
    "        #corrected_labels, corrected_predictions_resnet = predict_on_dataset(resnet_model, test_dataset)\n",
    "        corrected_labels, corrected_predictions_densenet = predict_on_dataset(densenet_model, test_dataset)\n",
    "        _, corrected_predictions_convnexttiny = predict_on_dataset(convnexttiny_model, test_dataset)\n",
    "\n",
    "        print(corrected_predictions_densenet)\n",
    "        corrected_predictions = np.transpose(np.vstack((#np.array(corrected_predictions_resnet), \n",
    "                                             np.array(corrected_predictions_densenet),\n",
    "                                             np.array(corrected_predictions_convnexttiny))))\n",
    "        print(np.shape(corrected_predictions))\n",
    "        print(corrected_predictions)\n",
    "        corrected_predictions = np.mean(corrected_predictions, axis=1) # np.sqrt(np.multiply(corrected_predictions[:, 0], corrected_predictions[:,1])) \n",
    "        print(corrected_predictions)\n",
    "        print(np.shape(corrected_predictions))\n",
    "\n",
    "        concat_labels = np.concatenate((concat_labels, corrected_labels), axis=0)\n",
    "        \n",
    "        print(\"Concat labels shape\")\n",
    "        print(np.shape(concat_labels))\n",
    "\n",
    "        concat_predictions = np.concatenate((concat_predictions, corrected_predictions), axis=0)\n",
    "        print(\"Concat predictions shape\")\n",
    "        print(np.shape(concat_predictions))\n",
    "        predict_on_performance = 1-(np.count_nonzero(tf.where(corrected_predictions < 0.5, 0, 1) - corrected_labels))/len(corrected_labels)\n",
    "        predict_score_mean = np.mean(corrected_predictions)\n",
    "        concat_predict_score_mean.append(predict_score_mean)        \n",
    "\n",
    "        print(\"Labels \" + str(corrected_labels))\n",
    "        print(\"Predictions = \" + str(tf.where(corrected_predictions < 0.5, 0, 1).numpy()))\n",
    "        print(\"Label length = \" + str(len(corrected_labels)))\n",
    "        print(\"Predictions length = \" + str(len(corrected_predictions)))\n",
    "        print(\"Model performance (predict_on) \" + str(predict_on_performance))\n",
    "        print(\"Prediction cumulative score = \" + str(predict_score_mean))\n",
    "        #get_performance(model, test_dataset)\n",
    "        results.append(predict_on_performance)\n",
    "        prob_avg.append(np.mean(corrected_predictions))\n",
    "        output_avg.append(np.mean(tf.where(corrected_predictions < 0.5, 0, 1)))\n",
    "        \n",
    "        participant_labels.append(corrected_labels[0])\n",
    "        print(participant_labels)\n",
    "        participant_predictions.append(0 if predict_on_performance < 0.5 else 1)\n",
    "\n",
    "        first_pass = False\n",
    "\n",
    "        print(\"Elapsed time = \" + str(time.time() - tic))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273df7a1-6f10-4922-9f21-840bcba4ab1e",
   "metadata": {},
   "source": [
    "## Single Clip Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8058f1f-3bcb-403c-a160-a959f967f125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### %matplotlib inline\n",
    "%matplotlib inline\n",
    "print(results)\n",
    "result_dict = []\n",
    "class_names = [\"Fail\", \"Pass\"]\n",
    "i = 0\n",
    "\n",
    "print(\"Overall accuracy is \" + str(np.mean(results)))\n",
    "print(np.shape(concat_predictions))\n",
    "print(np.shape(concat_labels))\n",
    "plot_confusion_matrix(concat_labels, concat_predictions, class_names, \"Result Images/clip_confusion.png\")\n",
    "plot_confusion_matrix_plotly(concat_labels, concat_predictions, class_names, \"Result Images/clip_confusion_plotly.png\")\n",
    "plot_confusion_matrix_plotly_no_normalize(concat_labels, concat_predictions, class_names, \"Result Images/clip_confusion_plotly.png\")\n",
    "plot_roc(concat_labels, concat_predictions,  \"Result Images/clip_roc.png\")\n",
    "get_performance_metrics(concat_labels, concat_predictions)\n",
    "print(concat_predictions)\n",
    "predicted_labels = tf.where(concat_predictions < 0.5, 0, 1)\n",
    "\n",
    "calculate_metrics(concat_labels, predicted_labels, class_of_interest=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bee081a-976f-4c80-9a9a-af16d1e459dd",
   "metadata": {},
   "source": [
    "# Participant Level Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78ab434-3b01-419a-a886-2fb13b5fc488",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "participant_predictions = []\n",
    "\n",
    "print(prob_avg)\n",
    "for score in prob_avg: # can also use prob_avg or output_avg\n",
    "    participant_predictions.append(1 if score > 0.5 else 0)\n",
    "    i=i+1\n",
    "\n",
    "plot_confusion_matrix(np.array(participant_labels), np.array(participant_predictions), class_names, \"Result Images/participant_confusion.png\")\n",
    "plot_confusion_matrix_plotly(np.array(participant_labels), np.array(participant_predictions), class_names, \"Result Images/participant_confusion_plotly.png\")\n",
    "\n",
    "print(concat_predict_score_mean)\n",
    "print(participant_labels)\n",
    "print(participant_predictions)\n",
    "plot_roc(participant_labels, participant_predictions,  \"Result Images/participant_roc.png\")\n",
    "get_performance_metrics(participant_labels, np.array(concat_predict_score_mean))\n",
    "predicted_participant_labels = tf.where( np.array(concat_predict_score_mean) < 0.5, 0, 1)\n",
    "calculate_metrics(participant_labels, predicted_participant_labels, class_of_interest=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa34aa2",
   "metadata": {},
   "source": [
    "# **Dummy Classifier to compare performance**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aa56cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dummy_clf = DummyClassifier(strategy=\"constant\", constant=1)\n",
    "dummy_clf.fit(None, concat_labels)\n",
    "dummy_predictions = dummy_clf.predict(np.ones((len(concat_labels),1)))\n",
    "get_performance_metrics(concat_labels, dummy_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
