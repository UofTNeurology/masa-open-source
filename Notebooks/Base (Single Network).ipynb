{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16c0c27b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import shutil\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "\n",
    "import math\n",
    "#import pandas as pd\n",
    "#import librosa\n",
    "#import librosa.display\n",
    "import glob\n",
    "import numpy as np\n",
    "#import seaborn as sns; sns.set(style='whitegrid')\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "from sklearn.utils import shuffle, class_weight\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from PIL import Image\n",
    "from tqdm import tqdm,tnrange,tqdm_notebook\n",
    "import tensorflow as tf\n",
    "from tqdm.keras import TqdmCallback\n",
    "from tensorflow.keras import backend as K \n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras import applications as app\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten,AveragePooling2D#, CenterCrop\n",
    "from tensorflow.keras.layers.experimental.preprocessing import CenterCrop\n",
    "from tensorflow.keras.layers import Dense,BatchNormalization,Dropout \n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.applications import EfficientNetB4, ResNet50, ResNet101, VGG16, MobileNet, InceptionV3, EfficientNetB2, densenet, ConvNeXtTiny\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "%matplotlib inline\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_type = 'convnexttiny'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d225229f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Helper functions (run me)\n",
    "\n",
    "def set_device():\n",
    "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "  if device != \"cuda\":\n",
    "      print(\"WARNING: For this notebook to perform best, \"\n",
    "          \"if possible, in the menu under `Runtime` -> \"\n",
    "          \"`Change runtime type.`  select `GPU` \")\n",
    "  else:\n",
    "      print(\"GPU is enabled in this notebook.\")\n",
    "\n",
    "  return device\n",
    "\n",
    "def set_device_tf():    \n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "      # Restrict TensorFlow to only use the first GPU\n",
    "      try:\n",
    "        tf.config.experimental.set_visible_devices(gpus, 'GPU')\n",
    "        print(gpus)\n",
    "      except RuntimeError as e:\n",
    "        # Visible devices must be set at program startup\n",
    "        print(e)\n",
    "    else:\n",
    "      print(\"No GPUs found\")\n",
    "\n",
    "#  Plotting function.\n",
    "def plot_accuracy_and_loss(history):\n",
    "  acc = history.history['accuracy']\n",
    "  val_acc = history.history['val_accuracy']\n",
    "\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  plt.figure(figsize=(8, 8))\n",
    "  plt.subplot(2, 1, 1)\n",
    "  plt.plot(acc, label='Training Accuracy')\n",
    "  plt.plot(val_acc, label='Validation Accuracy')\n",
    "  plt.legend(loc='lower right')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.ylim([min(plt.ylim()),1.05])\n",
    "  plt.title('Training and Validation Accuracy')\n",
    "\n",
    "  plt.subplot(2, 1, 2)\n",
    "  plt.plot(loss, label='Training Loss')\n",
    "  plt.plot(val_loss, label='Validation Loss')\n",
    "  plt.legend(loc='upper right')\n",
    "  plt.ylabel('Cross Entropy')\n",
    "  plt.ylim([np.min(np.concatenate((val_loss,loss)))-0.1,np.max(np.concatenate((val_loss,loss)))+0.1])\n",
    "  plt.title('Training and Validation Loss')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.show()\n",
    "  plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec0eb01a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "set_device_tf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84d4903b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data loading.\n",
    "def load_data(train_dir, test_dir):\n",
    "  BATCH_SIZE = 32 # 64 can fill up GPU memory!\n",
    "  IMG_SIZE = (224, 224)\n",
    "  AUTOTUNE = tf.data.AUTOTUNE\n",
    "    \n",
    "  if train_dir is not None:\n",
    "    train_dataset = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
    "                                                                  shuffle=True,\n",
    "                                                                  validation_split=.2, ##RECENT CHANGE\n",
    "                                                                  seed=123,\n",
    "                                                                  subset='training',\n",
    "                                                                  batch_size=BATCH_SIZE,\n",
    "                                                                  image_size=IMG_SIZE)\n",
    "\n",
    "    validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
    "                                                                  shuffle=True,\n",
    "                                                                  validation_split=.2, ##RECENT CHANGE\n",
    "                                                                  seed=123,\n",
    "                                                                  subset='validation',\n",
    "                                                                  batch_size=BATCH_SIZE,\n",
    "                                                                  image_size=IMG_SIZE)\n",
    "    train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    print('Number of train batches: %d' % tf.data.experimental.cardinality(train_dataset))\n",
    "  else:\n",
    "    train_dataset = None\n",
    "    validation_dataset = None\n",
    "        \n",
    "  if test_dir is not None:\n",
    "    test_dataset = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
    "                                                                  shuffle=False,\n",
    "                                                                  image_size=IMG_SIZE)\n",
    "    test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "  else:\n",
    "    test_dataset = None\n",
    "\n",
    "  return train_dataset, validation_dataset, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26ea8cb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_weights(train_dataset, validation_dataset):\n",
    "  num_fails = 0\n",
    "  num_passes = 0\n",
    "  for images, labels in train_dataset:\n",
    "      labels_np = labels.numpy()\n",
    "      passes = np.count_nonzero(labels_np)\n",
    "      num_passes = num_passes + passes\n",
    "      fails = len(labels_np) - passes\n",
    "      num_fails = num_fails + fails\n",
    "      \n",
    "  total = num_fails + num_passes\n",
    "  print('Train Examples:\\n    Total: {}\\n, Passes: {}, Fails: {} ({:.2f}% of total)\\n'.format(\n",
    "      total, num_passes, num_fails, 100 * num_fails / total))\n",
    "\n",
    "  # Class weights\n",
    "  weight_for_fail = (1 / num_fails) * (total / 2.0)\n",
    "  weight_for_passes = (1 / num_passes) * (total / 2.0)\n",
    "\n",
    "  class_weights = {0: weight_for_fail, 1: weight_for_passes}\n",
    "\n",
    "  print('Weight for class 0 (Fail): {:.2f}'.format(weight_for_fail))\n",
    "  print('Weight for class 1 (Pass): {:.2f}'.format(weight_for_passes))\n",
    "\n",
    "  # Number of validation classes\n",
    "  num_fails = 0\n",
    "  num_passes = 0\n",
    "  for images, labels in validation_dataset:\n",
    "    labels_np = labels.numpy()\n",
    "    passes = np.count_nonzero(labels_np)\n",
    "    num_passes = num_passes + passes\n",
    "    fails = len(labels_np) - passes\n",
    "    num_fails = num_fails + fails\n",
    "    \n",
    "  total = num_fails + num_passes\n",
    "  print('Validation Examples: Total: {}\\n, Passes: {}, Fails: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, num_passes, num_fails, 100 * num_fails / total))\n",
    "  \n",
    "  return class_weights\n",
    "\n",
    "def compute_weights_scipy(train_dataset):\n",
    "  num_fails = 0\n",
    "  num_passes = 0\n",
    "  concat_labels = []\n",
    "  for images, labels in train_dataset:\n",
    "      labels_np = labels.numpy()\n",
    "      concat_labels.extend(list(labels_np))\n",
    "      passes = np.count_nonzero(labels_np)\n",
    "      num_passes = num_passes + passes\n",
    "      fails = len(labels_np) - passes\n",
    "      num_fails = num_fails + fails\n",
    "    \n",
    "  print(concat_labels)\n",
    "  class_weights = class_weight.compute_class_weight(class_weight ='balanced',\n",
    "                                                     classes = np.unique(concat_labels),\n",
    "                                                     y = concat_labels)\n",
    "  print(\"Class weights (SCIPY): \" + str(class_weights))\n",
    "  return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb598523-4dee-42ba-8901-727ebba9e7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass DenseNetWithDropout(densenet.DenseNet121):\\n    def __init__(self, dropout_rate=0.5, *args, **kwargs):\\n        super(DenseNetWithDropout, self).__init__(*args, **kwargs)\\n        self.dropout_rate = dropout_rate\\n\\n        custom_layers = []\\n\\n        # Iterate through base model layers\\n        for layer in self.layers:\\n            custom_layers.append(layer)\\n\\n            # Add dropout layer after each transition block\\n            if isinstance(layer, layers.MaxPooling2D):\\n                custom_layers.append(layers.Dropout(self.dropout_rate))\\n\\n        self.layers = custom_layers\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "class DenseNetWithDropout(densenet.DenseNet121):\n",
    "    def __init__(self, dropout_rate=0.5, *args, **kwargs):\n",
    "        super(DenseNetWithDropout, self).__init__(*args, **kwargs)\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        custom_layers = []\n",
    "\n",
    "        # Iterate through base model layers\n",
    "        for layer in self.layers:\n",
    "            custom_layers.append(layer)\n",
    "\n",
    "            # Add dropout layer after each transition block\n",
    "            if isinstance(layer, layers.MaxPooling2D):\n",
    "                custom_layers.append(layers.Dropout(self.dropout_rate))\n",
    "\n",
    "        self.layers = custom_layers\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "baccf9b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "def get_model(training=True, base_learning_rate = 0.0001, IMG_SIZE = (224, 224), model_type = model_type):\n",
    "    IMG_SHAPE = IMG_SIZE + (3,)\n",
    "\n",
    "    ## Densenet, convnext, resnet50\n",
    "\n",
    "    base_model_trainable = True\n",
    "\n",
    "    if model_type != \"custom\":\n",
    "        if model_type == \"mobilenet\":\n",
    "            ## MOBILENETV2\n",
    "            base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                                          include_top=False,\n",
    "                                                          weights='imagenet')\n",
    "            preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "            fine_tune_at = 154 - 15\n",
    "        elif model_type == \"resnet\":\n",
    "            ## RESNET50\n",
    "            base_model = tf.keras.applications.resnet50.ResNet50(input_shape=IMG_SHAPE,\n",
    "                                                          include_top=False,\n",
    "                                                        weights='imagenet')\n",
    "            preprocess_input = tf.keras.applications.resnet50.preprocess_input\n",
    "            fine_tune_at = 175 # was 29\n",
    "        \n",
    "        elif model_type == \"densenet\":\n",
    "            print(\"DENSENET SELECTED\")\n",
    "            ## Densenet\n",
    "            base_model = tf.keras.applications.densenet.DenseNet121(input_shape=IMG_SHAPE,\n",
    "                                                          include_top=False,\n",
    "                                                        weights='imagenet')\n",
    "            preprocess_input = tf.keras.applications.densenet.preprocess_input\n",
    "            fine_tune_at = 427 - 20 #52 #35 #375 #312 #10 #427 - 100 #427 - 20\n",
    "        elif model_type == \"densenet with dropout\":\n",
    "            ## Densenet\n",
    "            base_model = DenseNetWithDropout(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "            preprocess_input = tf.keras.applications.densenet.preprocess_input\n",
    "            fine_tune_at = 300\n",
    "        elif model_type == \"vgg16\":\n",
    "            ## Vgg16\n",
    "            base_model = tf.keras.applications.vgg16.VGG16(input_shape=IMG_SHAPE,\n",
    "                                                        include_top=False,\n",
    "                                                      weights='imagenet')\n",
    "            preprocess_input = tf.keras.applications.vgg16.preprocess_input\n",
    "        elif model_type == \"convnexttiny\":\n",
    "            print(\"CONVNEXT SELECTED\")\n",
    "            # convnexttiny\n",
    "            base_model = ConvNeXtTiny(input_shape=IMG_SHAPE,\n",
    "                                      include_top=False,\n",
    "                                      weights='imagenet')\n",
    "            preprocess_input = tf.keras.applications.convnext.preprocess_input\n",
    "            fine_tune_at = 132 #126 #was 132\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "        #image_batch, label_batch = next(iter(train_dataset))\n",
    "        #feature_batch = base_model(image_batch)\n",
    "        print(\"Number of layers = \" + str(len(base_model.layers)))\n",
    "        \n",
    "   \n",
    "        if base_model_trainable:\n",
    "            base_model.trainable = True\n",
    "            base_learning_rate = base_learning_rate/10\n",
    "\n",
    "        \n",
    "            # Fine-tune from this layer onwards \n",
    "            print(\"Number of layers = \" + str(len(base_model.layers)))\n",
    "        \n",
    "            # Freeze all the layers before the `fine_tune_at` layer\n",
    "            for layer in base_model.layers[:fine_tune_at]:\n",
    "                layer.trainable = False\n",
    "            '''\n",
    "            # freeze all layers after a certain layer\n",
    "            for layer in base_model.layers[fine_tune_at:]:\n",
    "                layer.trainable = False\n",
    "            '''\n",
    "        else:\n",
    "             base_model.trainable = False\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        # Set the starting point for fine-tuning\n",
    "        base_model.trainable = True\n",
    "        fine_tune_at = None\n",
    "        base_learning_rate = base_learning_rate/100\n",
    "        for i, layer in enumerate(base_model.layers):\n",
    "            if isinstance(layer, tf.keras.layers.Conv2D) and layer.name.endswith(\"conv5_block1_1_conv\"):\n",
    "                fine_tune_at = i\n",
    "                break\n",
    "        \n",
    "        print(\"Starting fine tuning at layer = \" + str(fine_tune_at))\n",
    "        if fine_tune_at:\n",
    "            # Unfreeze all layers from the fine-tuning starting point\n",
    "            for layer in base_model.layers[:fine_tune_at]:\n",
    "                layer.trainable = False\n",
    "        else:\n",
    "            print(\"Fine-tuning starting point not found\")\n",
    "         \"\"\"\n",
    "       \n",
    "    \n",
    "\n",
    "        global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        #feature_batch_average = global_average_layer(feature_batch)\n",
    "        #print(feature_batch_average.shape)\n",
    "\n",
    "        prediction_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        #prediction_batch = prediction_layer(feature_batch_average)\n",
    "        #print(prediction_batch.shape)\n",
    "\n",
    "\n",
    "        inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "        x = preprocess_input(inputs)\n",
    "        x = base_model(x) #was training=False\n",
    "        x = global_average_layer(x)\n",
    "        x = tf.keras.layers.Dropout(0.8)(x, training=training)\n",
    "        outputs = prediction_layer(x)\n",
    "        model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "    elif model_type == \"custom\":\n",
    "        model = tf.keras.Sequential([\n",
    "          tf.keras.layers.Rescaling(1./255),\n",
    "          tf.keras.layers.Conv2D(12, 3, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "          tf.keras.layers.MaxPooling2D(),\n",
    "          tf.keras.layers.Conv2D(24, 3, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "          tf.keras.layers.MaxPooling2D(),\n",
    "          tf.keras.layers.Conv2D(48, 3, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "          tf.keras.layers.MaxPooling2D(),\n",
    "          tf.keras.layers.Flatten(),\n",
    "          tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "          tf.keras.layers.Dropout(0.6),\n",
    "          tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy']) # recent change - added weight decay, subsequently removed , weight_decay=0.0005\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbecfbc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_test_model(model_type):\n",
    "  test_model = get_model(training=False, model_type=model_type)\n",
    "  test_model.load_weights(\"Weights/\" + model_type + \".h5\")\n",
    "\n",
    "  return test_model\n",
    "\n",
    "def get_performance(model, test_dataset):\n",
    "  loss, accuracy = model.evaluate(test_dataset)\n",
    "  print('Test accuracy :', accuracy)\n",
    "  return accuracy\n",
    "\n",
    "def predict_on_dataset(model, dataset):\n",
    "    labels = []\n",
    "    predictions = []\n",
    "\n",
    "    for images, image_labels in dataset:\n",
    "        preds = model.predict(images)\n",
    "        predictions.extend(preds)\n",
    "        labels.extend(image_labels.numpy())\n",
    "\n",
    "    return np.array(labels).flatten(), np.array(predictions).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29ae32d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plotting functions\n",
    "def plot_image_classifications(validation_dataset):\n",
    "  class_names = [\"Fail\", \"Pass\"]\n",
    "\n",
    "  image_batch, label_batch = validation_dataset.as_numpy_iterator().next()\n",
    "  predictions = model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "  # Apply a sigmoid since our model returns logits\n",
    "  predictions = tf.nn.sigmoid(predictions)\n",
    "  predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "  print('Predictions:\\n', predictions.numpy())\n",
    "  print('Labels:\\n', label_batch)\n",
    "  print(predictions.numpy() - label_batch)\n",
    "\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  start = 0\n",
    "  stop = 10\n",
    "  for i in range(start,stop):\n",
    "    ax = plt.subplot(4, 5, i - start + 1)\n",
    "    plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "    plt.title(\"True: \" + class_names[label_batch[i]] + '\\n' + \"Pred: \" + class_names[predictions[i]])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "\n",
    "def calculate_metrics(labels, predicted_classes, class_of_interest=0):\n",
    "\n",
    "    # Get confusion matrix\n",
    "    cm = confusion_matrix(labels, predicted_classes)\n",
    "\n",
    "    # Get values for class of interest\n",
    "    TP = cm[class_of_interest, class_of_interest]\n",
    "    FP = np.sum(cm[:, class_of_interest]) - TP\n",
    "    FN = np.sum(cm[class_of_interest, :]) - TP\n",
    "    TN = np.sum(cm) - TP - FP - FN\n",
    "\n",
    "    # Calculate metrics\n",
    "    sensitivity = TP / (TP + FN)\n",
    "    specificity = TN / (TN + FP)\n",
    "    precision = precision_score(labels, predicted_classes, pos_label=class_of_interest)\n",
    "    recall = recall_score(labels, predicted_classes, pos_label=class_of_interest)\n",
    "\n",
    "    print(\"Sensitivity = \" + str(sensitivity))\n",
    "    print(\"Specificity = \" + str(specificity))\n",
    "    print(\"Precision = \" + str(precision))\n",
    "    print(\"Recall = \" + str(recall))\n",
    "\n",
    "    return sensitivity, specificity, precision, recall\n",
    "    \n",
    "def plot_confusion_matrix(label_batch, predictions, class_names, save_path):\n",
    "  predictions = tf.convert_to_tensor(predictions, dtype=tf.float32) # Convert to tensor  \n",
    "  predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "  cm = confusion_matrix(label_batch, predictions.numpy() , normalize='true')\n",
    "  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "  disp.plot()\n",
    "  plt.savefig(save_path, facecolor='white', dpi=300,\n",
    "              transparent=False)\n",
    "  plt.show()\n",
    "  plt.close('all')\n",
    "\n",
    "def plot_roc(label_batch, predictions, save_path):\n",
    "  fp, tp, _ = roc_curve(label_batch, predictions)\n",
    "\n",
    "  plt.plot(100*fp, 100*tp, label=\"ROC\", linewidth=2)\n",
    "  plt.xlabel('False positives [%]')\n",
    "  plt.ylabel('True positives [%]')\n",
    "  plt.xlim([-0.5,100])\n",
    "  plt.ylim([0,100.5])\n",
    "  plt.grid(True)\n",
    "  ax = plt.gca()\n",
    "  ax.set_aspect('equal')\n",
    "  plt.savefig(save_path, facecolor='white', dpi=300,\n",
    "              transparent=False)\n",
    "  plt.show()\n",
    "  plt.close('all')\n",
    "\n",
    "def get_performance_metrics(labels, predictions):\n",
    "  auc = roc_auc_score(labels, predictions)\n",
    "  predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "  print('Auc: %.3f' % auc)\n",
    "  precision = precision_score(labels, predictions, pos_label=0, average='binary')\n",
    "  recall = recall_score(labels, predictions, pos_label=0, average='binary')\n",
    "  f1 = f1_score(labels, predictions, pos_label=0, average='binary')\n",
    "  print('Precision: %.3f, Recall: %.3f, F-Score: %.3f,' % (precision, recall, f1))\n",
    "  print(classification_report(labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9be6777-f1ea-48a2-9729-08654f700d23",
   "metadata": {},
   "source": [
    "# Probe Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bec7db8f-cf70-4c0d-9390-83aae2bcccc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndensenet = tf.keras.applications.densenet.DenseNet121()\\nconvnexttiny = ConvNeXtTiny()\\nfor i, layer in enumerate(convnexttiny.layers):\\n    print(layer.name)\\n    if layer.name == \"convnext_tiny_stage_3_block_0_depthwise_conv\":\\n       print(i)\\n       target_layer = i\\nprint(\"Convnexttiny Target layer = \" + str(target_layer))\\n\\nprint(\"Target layer = \" + str(target_layer))\\nfor i, layer in enumerate(densenet.layers):\\n    print(layer.name)\\n    if layer.name == \\'conv5_block9_concat\\': #\"pool4_pool\":\\n       print(i)\\n       target_layer = i\\n\\nprint(\"Densenet Target layer = \" + str(target_layer))\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "densenet = tf.keras.applications.densenet.DenseNet121()\n",
    "convnexttiny = ConvNeXtTiny()\n",
    "for i, layer in enumerate(convnexttiny.layers):\n",
    "    print(layer.name)\n",
    "    if layer.name == \"convnext_tiny_stage_3_block_0_depthwise_conv\":\n",
    "       print(i)\n",
    "       target_layer = i\n",
    "print(\"Convnexttiny Target layer = \" + str(target_layer))\n",
    "\n",
    "print(\"Target layer = \" + str(target_layer))\n",
    "for i, layer in enumerate(densenet.layers):\n",
    "    print(layer.name)\n",
    "    if layer.name == 'conv5_block9_concat': #\"pool4_pool\":\n",
    "       print(i)\n",
    "       target_layer = i\n",
    "\n",
    "print(\"Densenet Target layer = \" + str(target_layer))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87d35fdf-e3e0-467b-8d5a-4194dc1bef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate scheduler\n",
    "def scheduler(epoch, lr):\n",
    "  if epoch < (45 if model_type is 'densenet' else 25): # convnext: 25, densenet: 40, resnet: 15\n",
    "    return lr\n",
    "  else:\n",
    "    return lr * tf.math.exp(-0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75df2bb-ea09-4b7a-8ee2-c369c51dc393",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num folds = 1\n",
      "../Audio Data/Data/Fold 0/Train/\n",
      "Found 4551 files belonging to 2 classes.\n",
      "Using 3641 files for training.\n",
      "Found 4551 files belonging to 2 classes.\n",
      "Using 910 files for validation.\n",
      "Number of train batches: 114\n",
      "DENSENET SELECTED\n",
      "Number of layers = 427\n",
      "Number of layers = 427\n",
      "Train Examples:\n",
      "    Total: 3641\n",
      ", Passes: 2402, Fails: 1239 (34.03% of total)\n",
      "\n",
      "Weight for class 0 (Fail): 1.47\n",
      "Weight for class 1 (Pass): 0.76\n",
      "Validation Examples: Total: 910\n",
      ", Passes: 614, Fails: 296 (32.53% of total)\n",
      "\n",
      "Epoch 1/50\n",
      "114/114 [==============================] - 19s 110ms/step - loss: 1.2046 - accuracy: 0.4622 - val_loss: 1.0786 - val_accuracy: 0.4604 - lr: 1.0000e-05\n",
      "Epoch 2/50\n",
      "114/114 [==============================] - 11s 95ms/step - loss: 1.1377 - accuracy: 0.4848 - val_loss: 1.0403 - val_accuracy: 0.5110 - lr: 1.0000e-05\n",
      "Epoch 3/50\n",
      "114/114 [==============================] - 11s 95ms/step - loss: 1.0739 - accuracy: 0.5188 - val_loss: 1.0048 - val_accuracy: 0.5341 - lr: 1.0000e-05\n",
      "Epoch 4/50\n",
      "114/114 [==============================] - 11s 94ms/step - loss: 1.0238 - accuracy: 0.5243 - val_loss: 1.0335 - val_accuracy: 0.5209 - lr: 1.0000e-05\n",
      "Epoch 5/50\n",
      "114/114 [==============================] - 11s 94ms/step - loss: 0.9797 - accuracy: 0.5493 - val_loss: 1.0061 - val_accuracy: 0.5385 - lr: 1.0000e-05\n",
      "Epoch 6/50\n",
      "114/114 [==============================] - 11s 96ms/step - loss: 0.9387 - accuracy: 0.5639 - val_loss: 0.9690 - val_accuracy: 0.5879 - lr: 1.0000e-05\n",
      "Epoch 7/50\n",
      "114/114 [==============================] - 11s 93ms/step - loss: 0.9204 - accuracy: 0.5776 - val_loss: 1.0010 - val_accuracy: 0.5571 - lr: 1.0000e-05\n",
      "Epoch 8/50\n",
      "114/114 [==============================] - 11s 96ms/step - loss: 0.9153 - accuracy: 0.5757 - val_loss: 0.9542 - val_accuracy: 0.5802 - lr: 1.0000e-05\n",
      "Epoch 9/50\n",
      "114/114 [==============================] - 11s 96ms/step - loss: 0.9043 - accuracy: 0.5946 - val_loss: 0.8516 - val_accuracy: 0.6363 - lr: 1.0000e-05\n",
      "Epoch 10/50\n",
      "114/114 [==============================] - 11s 95ms/step - loss: 0.8642 - accuracy: 0.6031 - val_loss: 0.8374 - val_accuracy: 0.6308 - lr: 1.0000e-05\n",
      "Epoch 11/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.8502 - accuracy: 0.6064"
     ]
    }
   ],
   "source": [
    "# top_dir =  \"Data/Chronological Fold May 3/\"\n",
    "top_dir = \"../Audio Data/Data/\"\n",
    "folds = sorted(glob.glob(top_dir + \"/*\"))\n",
    "num_folds = len(folds)\n",
    "print(\"Num folds = \" + str(num_folds))\n",
    "results = []\n",
    "validation_subject = []\n",
    "epochs =  50 if model_type is 'densenet' else 30 # convnext: 35, densenet: 45, resnet 20\n",
    "class_names = [\"Fail\", \"Pass\"]\n",
    "\n",
    "\n",
    "concat_predictions = []\n",
    "concat_predict_score_mean = []\n",
    "fold_labels = []\n",
    "prob_avg = []\n",
    "start_tic = time.time()\n",
    "first_pass = True\n",
    "for fold in folds:\n",
    "  tic = time.time()\n",
    "  training_dir = fold + \"/Train/\"\n",
    "  test_dir = fold + \"/Validation/\"\n",
    "  print(training_dir)\n",
    "\n",
    "  train_dataset, validation_dataset, test_dataset = load_data(training_dir, None)\n",
    "  model = get_model(training=True)\n",
    "\n",
    "  weights = compute_weights(train_dataset, validation_dataset)\n",
    "\n",
    "  # Early stopping and model checkpointing\n",
    "  early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=7, restore_best_weights=True)\n",
    "  #model_checkpoint = ModelCheckpoint('best_model.model', monitor='loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "  lr_scheduler_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "  history = model.fit(train_dataset,\n",
    "                    epochs=epochs,\n",
    "                     validation_data=validation_dataset,\n",
    "                    callbacks=[early_stopping, lr_scheduler_callback], class_weight=weights)\n",
    " \n",
    "  results = get_performance(model, train_dataset)\n",
    "\n",
    "  if first_pass:\n",
    "    print(model.summary())\n",
    "    first_pass = False\n",
    "    \n",
    "  plot_accuracy_and_loss(history)\n",
    "\n",
    "  \n",
    "  # Load best model\n",
    "  #model = load_model('best_model.model')\n",
    "\n",
    "  # Clear and proceed\n",
    "  #K.clear_session()\n",
    "  #del model\n",
    "\n",
    "print(results)\n",
    "print(\"Total elapsed time is \" + str(time.time() - start_tic))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7af96e2-2ff9-4933-ba6b-77106a35c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, predictions = predict_on_dataset(model, train_dataset)\n",
    "plot_roc(labels, predictions,  \"Result Images/train_clip_roc.png\")\n",
    "get_performance_metrics(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbbf52b-a2bb-48dd-a987-4cf66ca34044",
   "metadata": {},
   "source": [
    "# Save Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbad0b29-571b-4129-b2f5-f3216de498b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('Weights/' + model_type + '.h5' , overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fe5df1-ca02-4cfd-9efd-b5a057070d12",
   "metadata": {},
   "source": [
    "# Run on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92858e8-71fb-48cf-9d63-528d5d8827d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rootdir = top_dir + \"Fold 0/Test/\"\n",
    "results = []\n",
    "participant_labels = []\n",
    "participant_predictions = []\n",
    "concat_labels = []\n",
    "tic = time.time()\n",
    "\n",
    "test_model = get_model(training=False)\n",
    "test_model.load_weights(\"Weights/\" + model_type + \".h5\")\n",
    "\n",
    "\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for dir in dirs:\n",
    "        print(rootdir + dir)\n",
    "        _, _, test_dataset = load_data(None, rootdir + dir)\n",
    "        corrected_labels, corrected_predictions = predict_on_dataset(test_model, test_dataset)\n",
    "    \n",
    "        concat_labels = np.concatenate((concat_labels, corrected_labels), axis=0)\n",
    "        concat_predictions = np.concatenate((concat_predictions, corrected_predictions), axis=0)\n",
    "        predict_on_performance = 1-(np.count_nonzero(tf.where(corrected_predictions < 0.5, 0, 1) - corrected_labels))/len(corrected_labels)\n",
    "        predict_score_mean = np.mean(corrected_predictions)\n",
    "        concat_predict_score_mean.append(predict_score_mean)\n",
    "        \n",
    "\n",
    "        print(\"Labels \" + str(corrected_labels))\n",
    "        print(\"Predictions = \" + str(tf.where(corrected_predictions < 0.5, 0, 1).numpy()))\n",
    "        print(\"Label length = \" + str(len(corrected_labels)))\n",
    "        print(\"Predictions length = \" + str(len(corrected_predictions)))\n",
    "        print(\"Model performance (predict_on) \" + str(predict_on_performance))\n",
    "        #print(corrected_predictions)\n",
    "        print(\"Prediction cumulative score = \" + str(predict_score_mean))\n",
    "        get_performance(model, test_dataset)\n",
    "        results.append(predict_on_performance)\n",
    "        prob_avg.append(np.mean(corrected_predictions))\n",
    "        \n",
    "        participant_labels.append(corrected_labels[0])\n",
    "        participant_predictions.append(0 if predict_on_performance < 0.5 else 1)\n",
    "\n",
    "        print(\"Elapsed time = \" + str(time.time() - tic))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec960c0-c779-4c2c-abf6-60220d8f2967",
   "metadata": {},
   "source": [
    "## Single Clip Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0442db4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib inline\n",
    "result_dict = []\n",
    "i = 0\n",
    "#print(folds)\n",
    "for fold in folds:\n",
    "  result_dict.append({\"Fold\": fold, \"Accuracy\": results[i]})\n",
    "  i = i + 1\n",
    "#print((prob_avg))\n",
    "\n",
    "print(\"Overall accuracy is \" + str(np.mean(results)))\n",
    "plot_confusion_matrix(concat_labels, concat_predictions, class_names, \"Result Images/clip_confusion.png\")\n",
    "plot_roc(concat_labels, concat_predictions,  \"Result Images/clip_roc.png\")\n",
    "get_performance_metrics(concat_labels, concat_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bce1d4d-0b2d-4195-a012-24eed4800f09",
   "metadata": {},
   "source": [
    "# Participant Level Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d2ddeb-a895-43a1-8e54-f75f5b99b589",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "participant_predictions = []\n",
    "\n",
    "for score in concat_predict_score_mean: # can also use prob_avg\n",
    "    participant_predictions.append(1 if score > 0.5 else 0)\n",
    "    i=i+1\n",
    "\n",
    "\n",
    "plot_confusion_matrix(np.array(participant_labels), np.array(participant_predictions), class_names, \"Result Images/participant_confusion.png\")\n",
    "\n",
    "print(concat_predict_score_mean)\n",
    "print(participant_labels)\n",
    "print(participant_predictions)\n",
    "plot_roc(participant_labels, participant_predictions,  \"Result Images/participant_roc.png\")\n",
    "get_performance_metrics(participant_labels, np.array(concat_predict_score_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa34aa2",
   "metadata": {},
   "source": [
    "# **Dummy Classifier to compare performance**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aa56cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dummy_clf = DummyClassifier(strategy=\"constant\", constant=1)\n",
    "dummy_clf.fit(None, concat_labels)\n",
    "dummy_predictions = dummy_clf.predict(np.ones((len(concat_labels),1)))\n",
    "get_performance_metrics(concat_labels, dummy_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09e7023-ce94-4f28-a9bc-c67fc419af2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
